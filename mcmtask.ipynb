{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee343b6f-6098-406d-aac2-1257d4611cf3",
   "metadata": {},
   "source": [
    "# 赛题 [填写赛题编号，如: E题]：[填写赛题名称，如: 交通流量管控]\n",
    "\n",
    "> **团队成员**: 👨‍💻 @俊宇 (建模与编程), 📊 @队友A (数据分析), ✍️ @队友B (论文写作)\n",
    "> **文件版本**: V0.1 - 初始数据探索\n",
    "> **最后更新**: [请在此处填写日期和时间]\n",
    "\n",
    "---\n",
    "### **核心思路与模型框架**\n",
    "*在这个区域，用几句话初步描述你们团队讨论出的解题大方向*\n",
    "1. **问题一**: 通过轨迹匹配推断转向流量，并用K-Means进行时段划分。\n",
    "2. **问题二**: 建立排队论模型，利用遗传算法优化信号灯配时方案。\n",
    "3. ...\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bccb47d-bca8-4dcb-bbf1-e8d1e7506c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# 模块一：全局初始化 (Global Initialization)\n",
    "# ===================================================================\n",
    "\n",
    "# 导入所有可能用到的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "import pulp\n",
    "# ... import other libraries as needed\n",
    "\n",
    "# 全局美化设置\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 解决中文显示问题\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "sns.set_style('whitegrid') # 设置图表风格\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "print(\"✅ 指挥中心已启动，所有库准备就绪！(警告过滤器已开启)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8027ea85-f0dd-41d6-9658-f7cdd4a7759a",
   "metadata": {},
   "source": [
    "# ===================================================================\n",
    "# 模块二：数据加载与预处理 (Data Loading & Preprocessing)\n",
    "# 负责人: @队友A\n",
    "# ==================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c5210-465b-4643-8e9f-ea15fceb7a13",
   "metadata": {},
   "source": [
    "### 2.1 数据加载\n",
    "* **任务**: 加载题目附件中的所有数据文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa69bf-c683-4746-b6a2-30d8bca6f655",
   "metadata": {},
   "source": [
    "# 🗺️ Step 1: 数据收集 (Data Collection)\n",
    "> **🎯 目标**: 加载题目附件中的所有数据文件，**确认数据已成功读入**。\n",
    "> **🕵️‍♂️ 你的任务**: \n",
    "> 1. 将所有附件文件和本Notebook放在**同一个文件夹**下。\n",
    "> 2. 在下方代码单元格中，**修改`file_path_x`变量为正确的文件名**。\n",
    "> 3. 按 **Shift+Enter** 执行代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2040d3-1eec-402c-86fc-04c8b991dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 🔴 请在这里修改文件名 ---\n",
    "file_path_1 = \"附件1.xlsx\"\n",
    "file_path_2 = \"附件2.csv\"\n",
    "# file_path_3 = \"...\" # 如果有更多文件，在此处添加\n",
    "\n",
    "try:\n",
    "    # 尝试用Pandas读取数据，你的主要武器是pd.read_excel()和pd.read_csv()\n",
    "    df1 = pd.read_excel(file_path_1)\n",
    "    df2 = pd.read_csv(file_path_2, encoding='gbk') # CSV文件有时需要指定编码，如gbk\n",
    "    # df3 = ...\n",
    "    print(\"✅ 所有附件数据加载成功！\")\n",
    "    \n",
    "    print(\"\\n--- 附件1 数据预览 (前5行) ---\")\n",
    "    display(df1.head())\n",
    "    print(\"\\n--- 附件2 数据预览 (前5行) ---\")\n",
    "    display(df2.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ 文件未找到，请仔细检查文件名和路径是否完全正确: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 数据加载失败，可能是编码问题或其他错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9706b2-b5b4-4970-b1b9-d19fb1fa8382",
   "metadata": {},
   "source": [
    "# 🧭 Step 2: 数据探索 (Exploratory Data Analysis - EDA)\n",
    "> **🎯 目标**: 快速摸清每个数据集的“家底”（**结构、分布、缺失情况**），对数据建立宏观认知。\n",
    "> **🕵️‍♂️ 你的任务**:\n",
    "> 1. 逐个执行下方的代码单元格。\n",
    "> 2. **仔细观察**每个单元格的输出结果。\n",
    "> 3. 将你的**所有发现和疑惑**，都记录在最后的 **“🕵️‍♂️ 你的【侦察笔记】”** 区域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363aec0-a6e1-422c-bef2-39b310ba3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1 检查数据集df1 ---\n",
    "print(\"--- 🔬 [df1] 数据结构概览 (info) ---\")\n",
    "df1.info()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- 🔬 [df1] 数值型数据统计摘要 (describe) ---\")\n",
    "display(df1.describe())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- 🔬 [df1] 类别型数据统计摘要 (describe for objects) ---\")\n",
    "display(df1.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef205e-8da1-48b1-8ab6-8b091cf486f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.2 检查数据集df2 ---\n",
    "print(\"--- 🔬 [df2] 数据结构概览 (info)---\")\n",
    "df2.info()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- 🔬 [df2] 数值型数据统计摘要 (describe)---\")\n",
    "display(df2.describe())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- 🔬 [df2] 类别型数据统计摘要 (describe for objects)---\")\n",
    "display(df2.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c3303-ef54-426b-8bb2-5ef6af90d4fb",
   "metadata": {},
   "source": [
    "### 🕵️‍♂️ 你的【侦察笔记】:\n",
    "> **你的任务**: 这是**最重要**的一步！请像一个真正的侦探一样，在这里写下你从上面所有输出中得到的**初步发现、结论和疑问**。这对后续建模至关重要！\n",
    "> \n",
    "> *   **关于df1**: \n",
    ">     *   _例如: “df1共有X行Y列，数据类型均正确，看起来很干净，没有缺失值。”_\n",
    "> *   **关于df2**:\n",
    ">     *   _例如: “df2的‘销售额’列存在大量缺失值（缺失XXX个）。\"_\n",
    ">     *   _例如: “df2的‘单价’列，最小值是-99，这明显是异常值，需要处理。”_\n",
    ">     *   _例如: “df2的‘日期’列是object类型，需要转换成datetime类型才能进行时间序列分析。”_\n",
    "> *   **初步结论/猜想**:\n",
    ">     *   _例如: “看起来df1是商品信息表，df2是销售流水表，它们可以通过‘商品ID’关联起来。”_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e190bad-97fd-496f-a86d-991909c85e14",
   "metadata": {},
   "source": [
    "# 🧹 Step 3: 数据清洗 (Data Cleaning)\n",
    "> **🎯 目标**: 处理我们在探索阶段发现的**缺失值、异常值、重复值和错误数据类型**。\n",
    "> **🕵️‍♂️ 你的任务**: 根据你的【侦察笔记】，在下方代码块中，“对症下药”，编写代码清洗数据，并**在【清洗日志】中记录你的每一步操作和理由**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187e013-565e-422c-8cab-085bd97ec941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集副本进行操作，永远保留原始数据！\n",
    "df1_cleaned = df1.copy()\n",
    "df2_cleaned = df2.copy()\n",
    "\n",
    "print(\"--- 开始数据清洗流程 ---\")\n",
    "\n",
    "# 示例 1: 处理数据类型错误\n",
    "# df2_cleaned['日期'] = pd.to_datetime(df2_cleaned['日期'])\n",
    "# print(\"✅ ‘日期’列已成功转换为datetime类型。\")\n",
    "\n",
    "# 示例 2: 处理异常值\n",
    "# 在清洗前，我们先看看有多少异常值\n",
    "# negative_price_count = (df2_cleaned['单价'] < 0).sum()\n",
    "# print(f\"发现 {negative_price_count} 条单价为负数的异常记录。\")\n",
    "# # 将异常值替换为NaN，稍后与其他缺失值一同处理\n",
    "# df2_cleaned.loc[df2_cleaned['单价'] < 0, '单价'] = np.nan\n",
    "# print(\"✅ 已将负数单价替换为NaN。\")\n",
    "\n",
    "# 示例 3: 处理缺失值\n",
    "# print(\"\\n--- 清洗前的缺失值统计 ---\")\n",
    "# print(df2_cleaned.isnull().sum())\n",
    "# # 填充‘销售额’列\n",
    "# sales_median = df2_cleaned['销售额'].median()\n",
    "# df2_cleaned['销售额'].fillna(sales_median, inplace=True)\n",
    "# print(\"✅ ‘销售额’列缺失值已用中位数填充。\")\n",
    "\n",
    "print(\"\\n--- 🔴 (占位符) 请在此处添加你的数据清洗代码 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1ab7c-ea00-4f00-a51c-33968436c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集副本进行操作，永远保留原始数据！\n",
    "df1_cleaned = df1.copy()\n",
    "df2_cleaned = df2.copy()\n",
    "\n",
    "print(\"--- 开始数据清洗流程 ---\")\n",
    "\n",
    "# 示例 1: 处理数据类型错误\n",
    "# df2_cleaned['日期'] = pd.to_datetime(df2_cleaned['日期'])\n",
    "# print(\"✅ ‘日期’列已成功转换为datetime类型。\")\n",
    "\n",
    "# 示例 2: 处理异常值\n",
    "# 在清洗前，我们先看看有多少异常值\n",
    "# negative_price_count = (df2_cleaned['单价'] < 0).sum()\n",
    "# print(f\"发现 {negative_price_count} 条单价为负数的异常记录。\")\n",
    "# # 将异常值替换为NaN，稍后与其他缺失值一同处理\n",
    "# df2_cleaned.loc[df2_cleaned['单价'] < 0, '单价'] = np.nan\n",
    "# print(\"✅ 已将负数单价替换为NaN。\")\n",
    "\n",
    "# 示例 3: 处理缺失值\n",
    "# print(\"\\n--- 清洗前的缺失值统计 ---\")\n",
    "# print(df2_cleaned.isnull().sum())\n",
    "# # 填充‘销售额’列\n",
    "# sales_median = df2_cleaned['销售额'].median()\n",
    "# df2_cleaned['销售额'].fillna(sales_median, inplace=True)\n",
    "# print(\"✅ ‘销售额’列缺失值已用中位数填充。\")\n",
    "\n",
    "print(\"\\n--- 🔴 (占位符) 请在此处添加你的数据清洗代码 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b10bab-0e22-4830-b76e-a759fe0ed5b7",
   "metadata": {},
   "source": [
    "### ✍️ 你的【清洗日志】:\n",
    "> **你的任务**: 在这里详细记录你的**每一步清洗操作和选择该操作的理由**。这是论文中“数据预处理”章节的核心素材！\n",
    "> * _**日期格式统一**: 将‘日期’列统一转换为`YYYY-MM-DD`的datetime格式，方便后续按时间进行聚合分析。_\n",
    "> * _**异常值处理**: 将‘单价’中小于0的值替换为缺失值(NaN)。因为单价不可能是负数，这属于明显的异常数据。后续将与其他缺失值一同处理。_\n",
    "> * _**缺失值填充**: 对‘销售额’的缺失，我选择了**中位数**填充，因为在EDA阶段发现该数据分布高度右偏，中位数比均值更能抵抗极端值的影响，更能代表一般水平。_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52091cc2-77cd-46ce-931f-12b89f26fa91",
   "metadata": {},
   "source": [
    "# 🖇️ Step 4: 数据集成 (Data Integration)\n",
    "> **🎯 目标**: 将多个清洗干净的数据集合并(merge)成一个强大的“**主分析数据集**”。\n",
    "> **🕵️‍♂️ 你的任务**: 找到合适的关联键(key)，使用`pd.merge()`将df1_cleaned和df2_cleaned合并。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302efd73-fd8b-489b-bffd-4d24b2f36a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # --- 🔴 请在这里修改关联键'key_column_name' ---\n",
    "    # key_column_name = '商品ID' # 假设这是共同的列名\n",
    "    # master_df = pd.merge(df2_cleaned, df1_cleaned, on=key_column_name, how='left')\n",
    "    \n",
    "    # print(\"✅ 数据集成功合并！预览合并后的主数据集：\")\n",
    "    # display(master_df.head())\n",
    "    # print(\"\\n--- 合并后主数据集信息 ---\")\n",
    "    # master_df.info()\n",
    "    print(\"🖇️ (占位符) 请在此处编写你的数据集合并代码\")\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"❌ 合并失败，请检查两个数据表中的关联列名是否完全一致: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e27127-a23e-403c-bf66-de4389192442",
   "metadata": {},
   "source": [
    "# 🎨 Step 5 (Bonus): 初步可视化洞察\n",
    "> **🎯 目标**: 对整合后的干净数据，进行初步的可视化，寻找规律。\n",
    "> **🕵️‍♂️ 你的任务**: 尝试使用`sns.lineplot`, `sns.barplot`等，画1-2张你认为最有价值的图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83f5ef-f29b-4564-abab-6d0486bdb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例：分析每日的总销售额趋势\n",
    "# daily_revenue = master_df.groupby('日期')['销售额'].sum()\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# sns.lineplot(data=daily_revenue)\n",
    "# plt.title(\"每日总销售额趋势图\", fontsize=16)\n",
    "# plt.show()\n",
    "print(\"🎨 (占位符) 请在此处尝试你的第一个可视化分析！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f23a17-98eb-4bd2-be65-db9060b5c4ab",
   "metadata": {},
   "source": [
    "---\n",
    "### 🎉 恭喜！你已完成数据侦察与清洗的核心任务！🎉\n",
    "> **下一步行动**:\n",
    "> 1. 将这份Notebook文件保存，并命名为`[赛题编号]_Data_Report_V1.ipynb`。\n",
    "> 2. **在Notion的建模日志中，简要汇报你的核心发现**。\n",
    "> 3. **通知 @俊宇 (我) 进行Code Review，并讨论后续的建模方向**！\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338bb0ab-04b5-4397-8392-31c345a94aa0",
   "metadata": {},
   "source": [
    "\n",
    "# ===================================================================\n",
    "# --- [阶段性交付点] --- 数据分析师完成工作 ---\n",
    "# ==================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8fc71-d45a-46d7-8bb9-dca46d670c62",
   "metadata": {},
   "source": [
    "# ===================================================================\n",
    "# 模块三：模型构建与求解 (Modeling & Solving)\n",
    "# 负责人: @俊宇\n",
    "# ==================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c72e6-2ed1-4ed8-b441-a26928fb0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "**(Code) 代码单元格**\n",
    "```python\n",
    "# ... 在这里放置你问题一的模型代码 ...\n",
    "# kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "# ...```\n",
    "**(M) Markdown 单元格**\n",
    "```markdown\n",
    "### 3.2 [问题二的模型，如：信号灯优化模型]\n",
    "* **模型思路**: 建立一个以总通行时间最短为目标的线性规划模型...```\n",
    "**(Code) 代码单元格**\n",
    "```python\n",
    "# ... 在这里放置你问题二的模型代码 ...\n",
    "# prob = pulp.LpProblem(...)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2951626-8a3d-4746-9efb-4a70045198d0",
   "metadata": {},
   "source": [
    "# ===================================================================\n",
    "# 模块四：结果分析与可视化 (Result Analysis)\n",
    "# 负责人: @俊宇 & @队友B\n",
    "# ==================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9061d257-f2f5-4574-9e13-662deafe00a2",
   "metadata": {},
   "source": [
    "### 4.1 核心结果汇总\n",
    "* **任务**: 将模型求解出的关键结果，以清晰的表格和图表形式展示出来，并存为图片或文件，方便论文引用。\n",
    "* **(重要: 这里的结果，要和Notion指挥中心的“最终结果汇总区”保持绝对一致！)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d8235-95e6-41db-af34-06f61abd0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... 在这里放置所有用于生成最终结果表格和图表的代码 ...\n",
    "# final_result_df.to_excel(\"问题一结果.xlsx\")\n",
    "# plt.savefig(\"核心结果图.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "🏆 MCM 2025 (竞赛专用)",
   "language": "python",
   "name": "mcm_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
